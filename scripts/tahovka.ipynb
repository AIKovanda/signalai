{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d886767e-5739-4317-b0e0-dda388be4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from signalai.config import CONFIG_DIR, PIPELINE_SAVE_PATH\n",
    "from taskorganizer.pipeline import Pipeline\n",
    "from signalai.signal_tools.signal import SignalDataset, Signal\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from inceptiontime import InceptionBlock, InceptionModule\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87472a10-c33f-4717-ae8b-dbebccfc353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "def gauss_convolve(arr, window_length, rel_std):\n",
    "    window = signal.windows.gaussian(window_length, std=window_length * rel_std)\n",
    "    window = window / np.sum(window)\n",
    "    c = np.array([np.convolve(arr[i, :], window, mode='same') for i in range(arr.shape[0])])\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86a381e-2a34-403b-8ed7-8b06be69c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = CONFIG_DIR / \"processing\" / \"pipeline.yaml\"\n",
    "params_config_path = CONFIG_DIR / \"data_preparation\" / \"tahovka0.yaml\"\n",
    "pip = Pipeline(\n",
    "    config_path,\n",
    "    config_dir=CONFIG_DIR,\n",
    "    save_folder=PIPELINE_SAVE_PATH,\n",
    "    parameter_yamls=[params_config_path]\n",
    ")\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327cfeca-975b-4ad0-90be-6c9d42d0338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading datasets ['noise', 'tahovka_normal', 'tahovka_plastized'] to RAM: 100%|██████████| 15/15 [00:01<00:00,  8.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# df = pip.run(\"DatasetLoader\")\n",
    "# df.sample(4)\n",
    "gen_gen = pip.run(\"data_generator\")\n",
    "train_gen = gen_gen.get_generator(\"train\", log=0, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17146b42-3e7d-484c-8d49-65476578c0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 256.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.46 s, sys: 414 ms, total: 3.88 s\n",
      "Wall time: 3.91 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in trange(1000):\n",
    "    X, Y = next(train_gen)\n",
    "    _=torch.from_numpy(np.array(X)).to(device)\n",
    "    _=torch.from_numpy(np.array(Y)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a190e66a-feaa-42bd-82d8-58d286896a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inception_block1 = InceptionBlock(\n",
    "            in_channels=1,\n",
    "            n_filters=32,\n",
    "            kernel_sizes=[11, 21, 41],\n",
    "            bottleneck_channels=32,\n",
    "            use_residual=True,\n",
    "            activation=nn.SELU()\n",
    "        )\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        self.linear1 = nn.Linear(in_features=4 * 32 * 1, out_features=1)\n",
    "        self.out_activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.inception_block1(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(-1, 32 * 4 * 1)\n",
    "        x = self.linear1(x)\n",
    "        y = self.out_activation(x)\n",
    "        return y\n",
    "\n",
    "    \n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5aa413-c6e1-41b8-84aa-6a495c198c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8439e24-d8aa-4ec3-a925-5ae7855f69f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, output_name):\n",
    "    torch.save(model.state_dict(), output_name+\".pth\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_gen = gen_gen.get_generator(split=None, log=0, batch_size=32, x=\"X_all\", y=\"Y_all\")\n",
    "        result = []\n",
    "        for i in range(1072656250 // 32 // 32734):\n",
    "            X, _ = next(all_gen)\n",
    "            inputs = torch.from_numpy(np.array(X)).to(device)\n",
    "            result += list(model(inputs).cpu())\n",
    "\n",
    "        np_results = np.array([i.numpy() for i in result])[:,0]\n",
    "        plt.figure(figsize=(16,9))\n",
    "        sns.lineplot(y=gauss_convolve(np.expand_dims(np_results, 0), 30, 0.8)[0], x=range(len(np_results)))\n",
    "        plt.savefig(output_name+\".svg\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9174c84-a0b5-4b72-b753-8c284228adbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  0.67706859:   0%|          | 1/3000 [00:00<19:55,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  0.01696497:  10%|█         | 301/3000 [01:15<11:42,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  0.00295352:  20%|██        | 601/3000 [02:33<10:10,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  0.00155896:  30%|███       | 901/3000 [03:50<08:51,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  0.01259910:  40%|████      | 1201/3000 [05:06<07:43,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  0.01000556:  50%|█████     | 1500/3000 [06:22<06:27,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  0.00039937:  60%|██████    | 1801/3000 [11:11<05:00,  4.00it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:  0.00078201:  65%|██████▍   | 1949/3000 [11:48<04:22,  4.00it/s]"
     ]
    }
   ],
   "source": [
    "echo_step = 300\n",
    "save_step = 1500\n",
    "average_losses = 300\n",
    "batches_id = trange(3000)\n",
    "\n",
    "for train_batch in batches_id:  # loop over the dataset multiple times\n",
    "    \n",
    "    # optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "    X, Y = next(train_gen)\n",
    "    inputs = torch.from_numpy(np.array(X)).to(device)\n",
    "    labels = torch.from_numpy(np.array(Y)).type(torch.float32).unsqueeze(1).to(device)\n",
    "    # print(labels)\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print statistics\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    mean_loss = np.mean(losses[-average_losses:])\n",
    "    if mean_loss < 1e-5:\n",
    "        break\n",
    "        \n",
    "    batches_id.set_description(f\"Loss: {mean_loss: .08f}\")\n",
    "    if train_batch % echo_step == 0:\n",
    "        print()\n",
    "    \n",
    "    if train_batch % save_step == 0 and train_batch > 0:\n",
    "        evaluate(net, f\"tahovka/{train_batch}-noise-adam0.01\")\n",
    "        \n",
    "evaluate(net, f\"tahovka/{train_batch}-without_noise-adam_0.01\")\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
